{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAMB! TUTORIAL 5: THE DRIFT-DIFFUSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running through Google Colab, run this cell to install pyddm\n",
    "!pip -q install pyddm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyddm\n",
    "import pyddm.plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simulating the drift-diffusion model by hand\n",
    "We're going to simulate the drift-diffusion model in a variety of conditions and study of patterns of reaction times and responses that it produces, to develop some intutions on how the different parameters impact the behavior produced. The idea is to learning how the DDM works, but in practice, it is better to use an optimised library for simulating DDMs in your research.  In parts 2-4, we will learn to use one such library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Write a function to simulate the DDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ddm(drift_rate=.5, noise=.8, bound=1.2, dt=.01, T_dur=4):\n",
    "    \"\"\"\n",
    "    Simulate single run of discrete DDM (stores trajectory of decision variable)\n",
    "\n",
    "    [X, side, RT] = run_ddm(v, a, z, dt)\n",
    "    \n",
    "    Input:\n",
    "        drift_rate: drift rate\n",
    "        noise: standard deviation of noise\n",
    "        bound: the threshold(lower boundary corresponds to -a, upper boundary to a)\n",
    "        dt: time step for discretized version of dynamics\n",
    "        T_dur: total runtime, in seconds\n",
    "\n",
    "    Output:\n",
    "        X: vector with dynamics of the decision variable until hitting the boundary\n",
    "        side: +1 if DV hits the upper boundary, -1 if DV hits the lower boundary\n",
    "        RT: reaction time\n",
    "\n",
    "    \"\"\"\n",
    "    # FILL THIS IN\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have written this function, use it simulate 5 trials and plot dynamics of the decision variable and bounds\n",
    "Use parameter values: drift = 0.5, bound = 1.2, and no non-decision-time.\n",
    "Use time step dt = 0.001 and a duration of 4 sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound = 1.2\n",
    "noise = .8\n",
    "drift_rate = .5\n",
    "T_dur = 4\n",
    "dt = .001\n",
    "\n",
    "# FILL THIS IN\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Decision variable')\n",
    "plt.ylim((-bound-.2, bound+.2))\n",
    "plt.xlim(0, T_dur+.2)\n",
    "plt.axhline(-bound, c='r')\n",
    "plt.axhline(bound, c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat with 500 trials.  Add transparency of 0.01 to the lines so that you can still see the density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL THIS IN\n",
    "    \n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Decision variable')\n",
    "plt.ylim((-bound-.2, bound+.2))\n",
    "plt.xlim((0, T_dur+.2))\n",
    "plt.axhline(bound, c='r')\n",
    "plt.axhline(-bound, c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice with transparency that you can see the density of particles which hit a given point.  We will come back to this in Part II."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Plot the RT distribution\n",
    "Run the DDM 10000 times.  We don't care about the trajectories here, but we do care about the RT and the choice that was made. Plot a histogram, separately for correct and incorrect responses.\n",
    "Use parameters: drift = 0.5, bound = 1.2, noise = 0.8, dt=.005, T_dur = 4.  Also include a non-decision time of 0.3 s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_trials = 10000\n",
    "drift_rate = .5\n",
    "bound = 1.2\n",
    "noise = .8\n",
    "dt = .005\n",
    "T_dur = 4\n",
    "non_decision_time = .3\n",
    "\n",
    "# FILL THIS IN \n",
    "# Put correct and error response times into the list \"correct_rts\" and \"error_rts\" to use the plotting code below.\n",
    "        \n",
    "ax1 = plt.subplot(2,1,1)\n",
    "h = plt.hist(correct_rts, bins=np.arange(0, T_dur, dt*20))\n",
    "plt.title(\"Correct RT distribution\")\n",
    "plt.subplot(2,1,2, sharey=ax1)\n",
    "plt.hist(error_rts, bins=np.arange(0, T_dur, dt*20))\n",
    "plt.title(\"Error RT distribution\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Simulating the drift-diffusion model with PyDDM\n",
    "In practice, we generally want to perform simulations with a dedicated library instead of by hand.  This is because there are more efficient solutions than simulating individual trajectories.  For instance, many DDMs have closed-form mathematical expressions for the RT distribution, so we don't need to simulate individual trajectories.  For models that don't have closed-form solutions, simulators are still able to simulate much faster by simulating the entire probability distribution of evolving particle density instead of individual decisions one by one.  This also allows you to have a continuous estimate of the probability density function, instead of a histogram of responses.  In addition to being visually cleaner, it allows fitting the model using maximum likelihood.\n",
    "\n",
    "You may find it useful in this section and later sections to consult the [PyDDM documentation](https://pyddm.readthedocs.io/en/latest/), especially the [cookbook](https://pyddm.readthedocs.io/en/latest/cookbook/index.html), the [quick start guide](https://pyddm.readthedocs.io/en/latest/quickstart.html), and the [API documentation](https://pyddm.readthedocs.io/en/latest/apidoc/model.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Simulate 10000 trials of the drift-diffusion model with PyDDM and plot the RT distribution\n",
    "Hint: You will want to create a PyDDM model using the \"gddm\" function, solve it, and then use the \"sample\" function on the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyddm\n",
    "\n",
    "# FILL THIS IN \n",
    "# Put correct and error response times into the list \"correct_rts\" and \"error_rts\" to use the plotting code below.\n",
    "\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "plt.hist(correct_rts, bins=np.arange(0, T_dur, 20*.005))\n",
    "plt.title(\"Correct RT distribution\")\n",
    "plt.subplot(2,1,2, sharey=ax1)\n",
    "plt.hist(error_rts, bins=np.arange(0, T_dur, 20*.005))\n",
    "plt.title(\"Error RT distribution\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Simulate an infinite number of trials of the drift-diffusion model and plot the density\n",
    "Hint: Every \"solution\" object contains the full RT distribution as pdf(\"correct\") and pdf(\"error\"), so this should require fewer lines of code than (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyddm\n",
    "\n",
    "# FILL THIS IN \n",
    "# Name your model \"m\" and put correct and error response times into the\n",
    "# lists \"correct_pdf\" and \"error_pdf\" to use the plotting code below.\n",
    "\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "plt.plot(m.t_domain(), correct_pdf)\n",
    "plt.title(\"Correct RT distribution\")\n",
    "plt.subplot(2,1,2, sharey=ax1)\n",
    "plt.plot(m.t_domain(), error_pdf)\n",
    "plt.title(\"Error RT distribution\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Use the following code to explore how the RT distribution depends on drift, noise, and bound\n",
    "Note: The strings \"d\" and \"n\" are placeholders for a value which has not yet been fit to data.  There is nothing special about the strings \"d\" and \"n\", we could have used \"drift\" and \"noise\", \"param1\" and \"param2\", or any other strings.  All we need to do is specify the valid ranges for these parameters in the \"parameters\" argument to the \"gddm\" function.  In this caes, we let the drift vary from -2 to 2, and the noise vary from .1 to 1.5.  We will see this pattern coming up again and again.\n",
    "\n",
    "Note: Make sure the \"real-time\" checkbox is checked once the model gui starts in order to update the plot as you drag the sliders\n",
    "\n",
    "Another note: If you are running this notebook locally instead of on Google Colab, you can also run \"model_gui\" in addition to \"model_gui_jupyter\" to run the interface in a pop-up window instead of in the Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyddm\n",
    "from pyddm.plot import model_gui_jupyter\n",
    "# TODO: MODIFY THIS CODE TO ALSO ALLOW THE BOUND TO VARY.\n",
    "# (Notice how it has a similar effect to noise.  In practice, \n",
    "# you should never fit both bound and noise for this reason!)\n",
    "m = pyddm.gddm(drift=\"d\", noise=\"n\", parameters={\"d\": (-2, 2), \"n\": (.1, 1.5)}, T_dur=4, dt=.001)\n",
    "model_gui_jupyter(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fitting the drift-diffusion model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Fit a simple DDM for a single subject\n",
    "We will fit the DDM to a non-human primate subject from [Roitman and Shadlen (2002)](https://www.jneurosci.org/content/22/21/9475) performing the random dot motion task.\n",
    "\n",
    "[Download data](https://pyddm.readthedocs.io/en/latest/_downloads/bcc1102d5b69c49dac52b49536b87240/roitman_rts.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyddm\n",
    "import pyddm.plot\n",
    "import pandas\n",
    "\n",
    "#First, load the data we wish to use\n",
    "df_rt = pandas.read_csv(\"https://raw.githubusercontent.com/mwshinn/PyDDM/master/doc/downloads/roitman_rts.csv\")\n",
    "\n",
    "df_rt = df_rt[df_rt[\"monkey\"] == 1] # Only monkey 1\n",
    "\n",
    "# FILL THIS IN.\n",
    "# Create a PyDDM Sample named \"sample\" using the dataframe above.\n",
    "# Hint: see https://pyddm.readthedocs.io/en/latest/apidoc/model.html#pyddm.sample.Sample.from_pandas_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's fit a model that ignores the coherence.  It is probably not going to be a very good model, but it will show us how to fit a model in PyDDM.  We will fit the previous model we built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL THIS IN.\n",
    "# Create a model named \"m\" to use the plotting code below.  It should allow\n",
    "# drift to vary between -5 and 5, noise between .1 and 2, and non-decision \n",
    "# between 0 and .5.\n",
    "\n",
    "pyddm.plot.model_gui_jupyter(model=m, sample=sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL THIS IN.\n",
    "# Hint: it should be one function call on a method of \"m\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show information about the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the model gui again, but this time, to visualise the fit that we just performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyddm.plot.model_gui_jupyter(model=m, sample=sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fit is good, but it doesn't seem to fit the error RTs very well.  It also doesn't take into account the fact that different trials have different coherences of random dot motion.  Let's improve this model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Fitting a coherence-dependent DDM to a single subject\n",
    "\n",
    "Notice how behaviour is different depending on the coherence of the random dot motion.  So, we need our drift rate to depend on the coherence of the stimulus in each trial.  In the data provided, the coherence is saved as the column \"coh\".\n",
    "\n",
    "In PyDDM, \"coh\" is called a \"condition\" because it describes some property of the underlying trial.  In addition to depending on parameters, models may also depend on conditions.\n",
    "\n",
    "To implement a drift rate that depends on coherence, we must define the drift rate as a function.  Functions can be used to define any of the DDM parameters.  They may take conditions and parameters as arguments.  \n",
    "\n",
    "\n",
    "\n",
    "So, to incorporate coherence into the model, we must create a function which takes \"coh\" as an argument, as well as a scaling factor for the coherence.\n",
    "\n",
    "Note: in the future, for simplicity, we will make use of \"lambda function\" notation (also called \"anonymous functions\") to define function parameters.  This notation is shorter but equivalent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL ME IN\n",
    "# Define a function named \"drift_coherence\" which multiplies \"coh\" by a \n",
    "# drift rate, which we will call \"drift_scale\".  You will get an error in\n",
    "# the next cell if you do this incorrectly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can construct the final model and fit it to data.  Create a model that uses your new drift function and visualise it with your sample using pyddm.plot.model_gui_jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pyddm.gddm(drift=drift_coherence, noise=\"sigma\", nondecision=\"nd\",\n",
    "               parameters={\"drift_scale\": (-20, 20), \"sigma\": (.1, 2), \"nd\": (0, .5)},\n",
    "               conditions=[\"coh\"])\n",
    "\n",
    "pyddm.plot.model_gui_jupyter(model=m, sample=sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, fit your model to data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL ME IN\n",
    "# Should be similar to fitting your model above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And visualize the fitted model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyddm.plot.model_gui_jupyter(model=m, sample=sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) (optional) Plot the psychometric and chronometric functions\n",
    "The psychometric function shows the coherence/evidence on the x axis and the probability of a correct response on the y axis.  Likewise, the chronometric function shows the coherence/evidence on the x axis and the mean RT of correct responses on the y axis.\n",
    "\n",
    "Hint: PyDDM model Solutions (the output of m.solve()) have a prob(\"correct\") and prob(\"error\") methods, as well as mean_rt() function.\n",
    "\n",
    "Hint 2: PyDDM Samples have these methods too!  You might also want to use the \"subset\" method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL ME IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c*) (optional) Plot the psychometric and chronometric functions (the cheater way)\n",
    "\n",
    "PyDDM has a function built-in for visualizing psychometric and chronometric functions in the model GUI.  Try to plot it yourself above first, though!\n",
    "\n",
    "The psychometric function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyddm.plot.model_gui_jupyter(model=m, sample=sample, plot=pyddm.plot.plot_psychometric('coh'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chronometric function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyddm.plot.model_gui_jupyter(model=m, sample=sample, plot=pyddm.plot.plot_chronometric('coh'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Adding an explicit model of lapse rate\n",
    "What happens if the subject responds during the non-decision time?  The model predicts no responses, so in theory, the model should give a likelihood of zero.  (Do you understand why?) Hence, since the log of zero is negative infinity, we will have a negative log likelihood of infinity.  (More generally, if there is even one \"outlier\" response at a time when the model predicts there should be none, this will have a large effect on the model.)  But when you look at our data, there are indeed a few responses during the non-decision time.  So why is the likelihood finite?\n",
    "\n",
    "It is finite because we have been cheating a bit.  By default, PyDDM returns a mixture model.  We assume that X% of trials are generated by the DDM, and (100-X)% of trials are generated by some other process, for example, an evidence-independent probability distribution.  Bye default, PyDDM assumes 2% of trials are drawn from a uniform distribution.  This can be changed by using the \"mixture_coef\" argument to the \"gddm\" function - we can even fit this parameter to data!\n",
    "\n",
    "Below, modify our model to use an error distribution with a uniform distribution.  Use a fittable mixture ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL ME IN\n",
    "\n",
    "pyddm.plot.model_gui_jupyter(model=m, sample=sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(sample=sample, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Sample size estimation\n",
    "\n",
    "Suppose we will be performing an experiment with human participants.  Before collecting data, we want to make sure we will have enough trials to reliably estimate the model parameters from the model in 3b.\n",
    "\n",
    "Our plan is to have 200 trials - 50 for each coh=0, coh=.25, coh=.5, and coh=.75.  From our preliminary data, we estimate the parameters drift_scale=13.62, noise=1.33, nd=0.31.  Simulate 10 datasets using this model, and then fit the model to the generated data.  Plot the histogram of each of the three parameters compared to the true values.\n",
    "\n",
    "In a real experiment, we might want to simulate it 100 times or more to get a better estimate, but 10 times should be enough to get a good idea for now.\n",
    "\n",
    "Hint: When you solve a model, you can specify the conditions using conditions={\"coh\": xxx} as an argument\n",
    "\n",
    "Hint #2: You can add together samples to combine them!\n",
    "\n",
    "Hint #3: You can get parameters from a model using model.parameters() or model.get_model_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "N_REPEATS = 3\n",
    "SAMPLE_SIZE = 200\n",
    "TRUE_DRIFT_SCALE = 13.62\n",
    "TRUE_NOISE = 1.33\n",
    "TRUE_NONDECISION = 0.31\n",
    "\n",
    "# First create two versions of the model, one to simulate the data, and one to fit to the simulated data.\n",
    "\n",
    "# FILL ME IN\n",
    "# Name the models m_fit and m_sim\n",
    "\n",
    "# For each iteration of this loop, we create four samples, combine them\n",
    "# through addition, and then fit the model above with this artificial data\n",
    "params = []\n",
    "for i in range(0, N_REPEATS):\n",
    "    print(\"starting loop\", i)\n",
    "    # FILL ME IN\n",
    "    params.append(m_fit.get_model_parameters())\n",
    "\n",
    "# Convert to a numpy array for ease\n",
    "params = np.asarray(params)\n",
    "\n",
    "# Plot the histogram for each parameter\n",
    "plt.subplot(3,1,1)\n",
    "plt.hist(params[:,0])\n",
    "plt.axvline(TRUE_DRIFT_SCALE, c='k', linewidth=3)\n",
    "plt.title(m_fit.get_model_parameter_names()[0])\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.hist(params[:,1])\n",
    "plt.axvline(TRUE_NOISE, c='k', linewidth=3)\n",
    "plt.title(m_fit.get_model_parameter_names()[1])\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.hist(params[:,2])\n",
    "plt.axvline(TRUE_NONDECISION, c='k', linewidth=3)\n",
    "plt.title(m_fit.get_model_parameter_names()[2])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Generalized drift-diffusion models\n",
    "Generalized drift-diffusion models (GDDMs) allow going beyond the standard model parameters of the DDM.  Instead of drift, noise, and bound being fixed values, GDDMs allow them to be functions which may vary across time.  For example, this allows modelling tasks which have evidence that changes over time.  It also allows these to have complex, non-linear relationships with any number of task conditions and use any number of parameters.  For example, it is possible to model multisensory integration, with different streams of evidence contributing non-linearly to drift rate.  Furthermore, it also allows integration to be leaky (i.e. forgetting) or unstable (i.e. biasing early evidence), as well as representing an urgency signal (e.g. bounds which collapse over time).  There is evidence that these model properties are useful for modelling RTs in overtrained human or animal subjects.\n",
    "\n",
    "All of these exercises are optional and do not depend on each other - feel free to skip around and do those which are of greatest interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Collapsing boundaries\n",
    "Sometimes, especially in the case of overtrained animals, more evidence may be needed to make a decision earlier in the trial compared to later in the trial.  Construct, visualise, and fit a model with exponentially-boundaries to the data from (3).  It might be a bit slower when you call model.fit() since this model cannot be solved analytically.\n",
    "\n",
    "To do this, you can use the magic argument \"t\" to the drift function, representing the current time in the trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL ME IN\n",
    "# Name your model \"m\"\n",
    "\n",
    "pyddm.plot.model_gui_jupyter(model=m, sample=sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(sample=sample, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Leaky integration\n",
    "Leaky integration occurs when the decision variable is constantly being pushed back to zero (a stable fixed point at zero).  This models forgetting, or alternatively, prioritising more recent evidence.  This is implemented in the model by making the drift rate depend on the position of the particle at any given time.  You can use the magic argument \"x\" in the drift function, representing the position of the particle.  Construct and visualise a leaky integration model by modifying the model from Section 3b.  Optionally, you may fit it to data, but it may take a few minutes since this model has no closed-form solution.  Note that leak can be negative: this is also called \"unstable integration\", and corresponds to an unstable fixed point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL ME IN\n",
    "# Name your model \"m\"\n",
    "\n",
    "\n",
    "pyddm.plot.model_gui_jupyter(model=m, sample=sample)\n",
    "\n",
    "# m.fit(sample=sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Side bias\n",
    "In our dataset, we also have information about which side the monkey chose to get the correct answer (\"trgchoice\" in the Roitman dataset, which has values \"1\" or \"2\").  Let's use a GDDM to implement a side bias.\n",
    "\n",
    "There are two common ways to implement a side bias.  The first is to assume that the biased side causes a constant offset bias on the drift rate.  So, in the 0% coherence condition, the drift rate will be towards the biased side.  Likewise, in a strong evidence condition, the drift rate will be stronger if it is on the same side as the bias.  This can be implemented by adding \"trgchoice\" as a \"required_condition\" to the drift rate and a parameter \"side_bias\" to describe the magnitude of the bias.  Then, when computing the drift function, add \"side_bias\" to the result if it is on the preferred side, and otherwise, subtract \"side_bias\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL ME IN\n",
    "# Name your model \"m\"\n",
    "                \n",
    "pyddm.plot.model_gui_jupyter(model=m, sample=sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other way is to assume that there is an offset in the starting position: instead of starting at zero, we can use the \"starting_point\" argument to the \"gddm\" function.\n",
    "\n",
    "See the [PyDDM documentation](https://pyddm.readthedocs.io/en/latest/cookbook/initialconditions.html#biased-initial-conditions) for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL ME IN\n",
    "# Name your model \"m\"\n",
    "\n",
    "pyddm.plot.model_gui_jupyter(model=m, sample=sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Distributions of starting positions and non-decision time\n",
    "Suppose that, instead of starting at the position 0, the starting position of the integrator was pulled from a uniform distribution (where the size is a fittable parameter), and the non-decision time is pulled from a normal distribution with fittable mean and standard deviation.\n",
    "\n",
    "In PyDDM, if the functions for \"nondecision\" or \"starting_position\" return a vector instead of a number, they are assumed to be distributions.  When defining the functions, the magic argument \"x\" contains all possible starting positions, and \"T\" contains all possible time positions.\n",
    "\n",
    "Hint: If you don't want to write the pdf for these probability distributions yourself, scipy has several distributions built-in within the scipy.stats module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FILL ME IN\n",
    "# Name your model \"m\"\n",
    "\n",
    "pyddm.plot.model_gui_jupyter(model=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Evidence which changes over time\n",
    "Evidence is not always the same over time.  For instance, many tasks present discrete pulses of evidence.  Others may have evidence which is constantly fluctuating (e.g. changes in motion energy).\n",
    "\n",
    "To mode this in PyDDM, we need to create a custom Drift object, as we did above.  But this time, the get_drift function should use the \"t\" function argument.\n",
    "\n",
    "Suppose we have a task which contains two pulses of sensory evidence.  Each pulse can be a different strength.  Outside of the pulses, there is no sensory evidence.  The first pulse lasts from 0.3 s to 0.6 s, and the second from 1.0 to 1.2 s.  Let the magnitude of each be given by the conditions \"pulse1\" and \"pulse2\".\n",
    "\n",
    "Build a model of this task and check out the trippy RT distributions in the model_gui.\n",
    "\n",
    "Hint: When you view the model in the model GUI, you need to specify the conditions to view.  Let's try pulse strengths 0, .2, .4, and .6 for each pulse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL ME IN\n",
    "# Name your model \"m\"\n",
    "                \n",
    "pyddm.plot.model_gui_jupyter(m, conditions={\"pulse1\": [0, .2, .4, .6], \"pulse2\": [0, .2, .4, .6]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Your own task\n",
    "\n",
    "If you made it to here, try to build a GDDM of some aspect of your own data.  TAs will be happy to give you some suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
